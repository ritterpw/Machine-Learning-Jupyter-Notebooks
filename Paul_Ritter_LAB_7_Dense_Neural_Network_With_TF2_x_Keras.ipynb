{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Paul_Ritter_LAB-7_Dense_Neural_Network_With_TF2.x_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VAhuxLlqsaK"
      },
      "source": [
        "# **ISAT 449 - Emerging Topics in Applied Data Science**\n",
        "### Using TensorFlow 2.x Keras Layers\n",
        "## Building a Dense Neural Network with TensorFlow 2.x Keras\n",
        "\n",
        "The previous lesson was just to get you used to the learning environment and the concepts involved in building machine learning models. Now, in this part, let's really see the power andease of use in builing more sophisticated models with the TensorFlow 2.x implementation of Keras, tf.keras\n",
        "\n",
        "## **Learning Objectives**\n",
        "\n",
        "\n",
        "\n",
        "*   Learn how to build a Dense neural networks with TensorFlow 2.x and Keras\n",
        "*   Learn different appraches to stacking layers or artificial neurons to build multi-layer machine learning models\n",
        "*   Construct models for Linear regression and classification\n",
        "*   Train the model on NumPy generated data\n",
        "*   Create simple datasets for exploring model architectures\n",
        "*   Use the model's history to plot the loss and accuracy during training\n",
        "*   Check the model's accuracy with your test data\n",
        "\n",
        "### **Let's import tensorflow and some helper modules**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km7E3fj5p7Sv",
        "outputId": "c7869885-ed01-40ae-9f6b-ad00dfcc54b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "print(\"Tensorflow Version:\", tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow Version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwzXkEBTtPj8"
      },
      "source": [
        "## **Dense Models**\n",
        "### **Sequential model**\n",
        "\n",
        "In Keras, you assemble layers to build models. A model is (usually) a stack or graph of layers. The most common type of model is a stack of layers: the tf.keras.Sequential model.  Let's use the tf.keras.Sequential model build a simple, fully-connected feed-forward neural network (i.e. multi-layer perceptron) which is also called a Dense neural network. tf.keras has several ways of building models. \n",
        "\n",
        "Below we illustrate two of the methods for building neural networks with tf.keras\n",
        "\n",
        "### **Method 1- Explicitly Creating and Stacking the layers in a Python List**\n",
        "\n",
        "Using the Python lists explicitly as we did in the last lesson emphasized the core sequential nature of building models with tf.keras\n",
        "\n",
        "### **Practice Problem 1: Build a Dense neural Network for Regression**\n",
        "\n",
        "Let's build a model of a fully-connected feed-forward neural network (i.e. multi-layer perceptron) also called a Dense neural network. The tf.keras Sequential class is used to implement the feed-forward neural network. We will build a regression model using a Dense network and numpy generated data.\n",
        "\n",
        "## **Generate some data using NumPy**\n",
        "\n",
        "For illustrative purposes, let's also create in-memory, small, NumPy generated dataset arrays to train and evaluate our model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYzrAFxLtLlN"
      },
      "source": [
        "#Generate a 2-D array with 1000 rows, each row containing 5 random floats from 0 to 1\n",
        "x_train = np.random.normal(size =(1000, 5))\n",
        "#Generate a 1-D array containing 1000 random integers from 0 to 5\n",
        "y_train = np.random.randint(2, size=1000)\n",
        "#Generate a 2-D array with 100 rows, each row containing 5 random floats from 0 to 1\n",
        "x_test = np.random.normal(size = (100,5))\n",
        "#Generate a 1-D array containing 100 random integers from 0 to 5\n",
        "y_test = np.random.randint(2, size = (100))\n",
        "#y_train"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFvnzP2OiD_j"
      },
      "source": [
        "### tf.keras needs the the shape of the input feature array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E15vpJEFv7Nh",
        "outputId": "682c522f-52ba-46c1-c860-50448c26b135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# quick way to get input shape for tensorflow-keras \n",
        "x_train.shape[1:]\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "print('input shape of the feature matrix is: ', input_shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape of the feature matrix is:  (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Q5xkzHh8yG"
      },
      "source": [
        "## **Create the layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_UpqPqYwCtB"
      },
      "source": [
        "# the input layer to the model informs it of the shape of you features dataset\n",
        "l0 = tf.keras.layers.Dense(units = 32, input_shape = input_shape) # output layer has 32 neurons\n",
        "\n",
        "# Adds a densely-connected layer with 16 units to the model:\n",
        "l1 = tf.keras.layers.Dense(units = 16, activation = 'relu')\n",
        "\n",
        "# Adds another densely-connected layer with 1 units to the model\n",
        "l2 = tf.keras.layers.Dense(units = 1) #regression. this output layer has no activation function!"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWjZT6cQicdU"
      },
      "source": [
        "## **Assemble the layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwoNtWRmwpC7"
      },
      "source": [
        "# build the Sequential model as a list. recall, the elements in a list are indexed according to\n",
        "# a definite sequence(ordered!) and the indexing of a list begins with 0 being the first index.\n",
        "model = tf.keras.Sequential([l0, l1, l2])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YUXEh16jNLv"
      },
      "source": [
        "## **Compile and Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn8H9Aopw3cA",
        "outputId": "c9bfe919-dfb8-41d4-e5f3-7a8b243de5d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer= 'SGD',\n",
        "              loss = 'mse',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# train the model by calling the fit method \n",
        "history = model.fit(x_train, y_train, validation_split=0.1, epochs=5, verbose = 1) #use 10% of training set for validation"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "29/29 [==============================] - 1s 12ms/step - loss: 0.4576 - accuracy: 0.5022 - val_loss: 0.3293 - val_accuracy: 0.4100\n",
            "Epoch 2/5\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.5156 - val_loss: 0.3034 - val_accuracy: 0.4300\n",
            "Epoch 3/5\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.5267 - val_loss: 0.2914 - val_accuracy: 0.4400\n",
            "Epoch 4/5\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.5200 - val_loss: 0.2796 - val_accuracy: 0.4400\n",
            "Epoch 5/5\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.5211 - val_loss: 0.2705 - val_accuracy: 0.4500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ShygkvXj2D6"
      },
      "source": [
        "## **Display metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf5DxhHqx_TP",
        "outputId": "aee4133f-a3b0-4304-87a0-16f22377a3a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "# printing model metrics\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2e4f0434-e2b3-4de0-820f-e2fd56200a7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.457552</td>\n",
              "      <td>0.502222</td>\n",
              "      <td>0.329283</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.292102</td>\n",
              "      <td>0.515556</td>\n",
              "      <td>0.303402</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.277269</td>\n",
              "      <td>0.526667</td>\n",
              "      <td>0.291357</td>\n",
              "      <td>0.44</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.268866</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.279630</td>\n",
              "      <td>0.44</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.263077</td>\n",
              "      <td>0.521111</td>\n",
              "      <td>0.270493</td>\n",
              "      <td>0.45</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e4f0434-e2b3-4de0-820f-e2fd56200a7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e4f0434-e2b3-4de0-820f-e2fd56200a7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e4f0434-e2b3-4de0-820f-e2fd56200a7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0  0.457552  0.502222  0.329283          0.41      0\n",
              "1  0.292102  0.515556  0.303402          0.43      1\n",
              "2  0.277269  0.526667  0.291357          0.44      2\n",
              "3  0.268866  0.520000  0.279630          0.44      3\n",
              "4  0.263077  0.521111  0.270493          0.45      4"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOSaWvGikMHf"
      },
      "source": [
        "## **Plot loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp5Md829kSey",
        "outputId": "903bcc88-eb8a-4111-a747-92626c25113c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sF0xRhKkgXH"
      },
      "source": [
        "## **Evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8HtVsvJkmur",
        "outputId": "54abfb74-c2ed-4460-e00c-278e337c3423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Finally, let's compare how the model performs on the test dataset:\n",
        "test_loss,test_acc = model.evaluate(x_test,y_test,verbose=1)\n",
        "print('The test set loss is:{0:0.4f} and the test set accuracy is:{1:0.4}%'.format(test_loss,100*test_acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.5200\n",
            "The test set loss is:0.2781 and the test set accuracy is:52.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_svQ6vDkzaF"
      },
      "source": [
        "## **Make a prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4sTpL5pk4Er",
        "outputId": "168226c1-b196-4c05-dfc1-d0ee32363ae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict([[1,2,3,4,5]])\n",
        "#print(x_test[4:5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3494017]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaE4gsPEk-Uj"
      },
      "source": [
        "## **Comments**\n",
        "\n",
        "tf.keras.model.compile takes three important arguments:\n",
        "\n",
        "\n",
        "*   optimizer: This object specifies the training procedure. Pass it optimizer instances from the tf.train module, such as tf.train.AdamOptimizer, tf.train.RMSPropOptimizer, or tf.train.GradientDescentOptimizer.\n",
        "*   loss: The function to minimize during optimization. Common choices include mean square error (mse), categorical_crossentropy, and binary_crossentropy. Lossfunctions are specified by name or by passing a callable object from the tf.keras.losses module.\n",
        "*   metrics: Used to monitor training. These are string names or callables from the tf.keras.metrics module.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KfD9hUr1VDR"
      },
      "source": [
        "## **Method 2 - Create the Sequential model by passing a list of layer instances to the constructor**\n",
        "\n",
        "Previously we demonstated model building using a Python list such that:\n",
        "\n",
        "\n",
        "\n",
        "*   Each layer of units (neurons) could be created outside the Sequential Class\n",
        "*   Then they could all be passed to the Sequential model as a list in a linear stack of layers.\n",
        "*   When a model is created upon instantiation of the Sequential Class, this list is passed to its constructor as a list of layer instances\n",
        "\n",
        "There are several other methods to create and stack layers with tf.keras such as the .add() method. You should explore them! For the remainder of this course we the Sequential class with layer created inside the class. This is the one of the simplest and widely used approaches to quickly create and stack the layers of artificial neurons in dense networks. Let's use this approach to build a fully-connected network (i.e. multi-layer perceptron) feed- forward network (called a Dense Neural Network) to solve a simple binary classifcation problem.\n",
        "\n",
        "\n",
        "Practice Problem 2\n",
        "### **bold text**\n",
        "\n",
        "Build a machine learning model for **binary classification** that can classify colors into either red or blue based on the three RGB color channels, R (Red), G (Green), and B (Blue).\n",
        "\n",
        "### **Solution**\n",
        "\n",
        "*   It can be solved linearly(don't need hidden layers) but I chose to use one hidden layer.\n",
        "*   There will be a single neuron in the output layer with an activation function.\n",
        "*   The network architecture is easy to envision (draw it!)\n",
        "\n",
        "The workflow is:\n",
        "\n",
        "*   Create the training data (features and labels)\n",
        "*   Building and connect the neural networks layers\n",
        "*   Select loss function and optimizer to assess the prediction error\n",
        "*   Compile and train the model\n",
        "*   Use the model's history to plot the loss and accuracy during training\n",
        "*   Check the model's prediction accuracy with test data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxhHVxsK1Xz7",
        "outputId": "fd009b3c-9fa7-45d6-d4ba-5af13bf72b72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create training dataset  \n",
        "x_train = np.array([[255, 0,0],\n",
        "                    [248,80,68],\n",
        "                    [0,0,255],\n",
        "                    [67,15,210]], dtype='float')\n",
        "\n",
        "# Create training labels \n",
        "# y_train = np.array([1, 1, 0, 0],    dtype='float')\n",
        "y_train = np.array([[1], [1], [0], [0] ], dtype = 'float')\n",
        "\n",
        "# model has an input layer and a hidden and output layer, each with one neuron (units)\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(units = 10 , input_shape = (3,)),\n",
        "        tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "#compile the model\n",
        "learning_rate = 0.1\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr = learning_rate),\n",
        "    loss = tf.keras.losses.binary_crossentropy,\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "#show model architecture\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs= 100, verbose = 0)\n",
        "\n",
        "test_set = [[248,80,68], [0,0,255]]\n",
        "\n",
        "print('The model predicts for the two inputs', model.predict(test_set))\n",
        "\n",
        "print('\\nThe expected value are: [1] for [248, 80, 68] and [0.0] for [0, 0, 255]')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 10)                40        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model predicts for the two inputs [[1.]\n",
            " [0.]]\n",
            "\n",
            "The expected value are: [1] for [248, 80, 68] and [0.0] for [0, 0, 255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYBsr851rWzR"
      },
      "source": [
        "### **Note**\n",
        "\n",
        "The binary cross-entropy is just a technical term for the cost function in the logistic regression, and the categorical cross-entropy is its generalization for multiclass predictions via softmax, which we will cover in the section estimating class probabilities in multiclass classification via the softmax function later in this course.\n",
        "\n",
        "So this simple model is performing quite well and you have now trained a simple binary classifier with ~98% accuracy on this very small dataset. However, you should not take the results to seriously because with a dataset this small, the model is very likely overfitting, i.e memorizing the pattern.\n",
        "\n",
        "### **Practice Problem 3: MNIST classification with TensorFlow and Keras!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCd0pNmD2RcT",
        "outputId": "3274c5af-0f95-4170-cffd-af672c4937a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "\n",
        "#get MNIST data from repo\n",
        "mnist=tf.keras.datasets.mnist\n",
        "\n",
        "#load mnist data\n",
        "(images_train, labels_train), (images_test, labels_test) = mnist.load_data()\n",
        "\n",
        "#normalize training set data\n",
        "images_train, images_test = images_train / 255.0, images_test / 255.0\n",
        "\n",
        "#create list of class names as strings\n",
        "class_names = ['zero', 'one', 'two', 'three', 'four', 'five', 'six',\n",
        "               'seven', 'eight', 'nine']\n",
        "\n",
        "# Note the input layer to the model. It consist of the image which gets flattened\n",
        "# into a one-dimensional vector (array) with 784 entries reprenting the pixel values\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = (28,28)), \n",
        "    tf.keras.layers.Dense(units = 512 , activation = 'relu'),\n",
        "    tf.keras.layers.Dense(units = 10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(images_train, labels_train, epochs =1, verbose = 1)\n",
        "\n",
        "\n",
        "model.evaluate(images_test, labels_test)\n",
        "\n",
        "# make prediction\n",
        "print(model.predict(images_test[0].reshape(-1, 28,28)))\n",
        "\n",
        "#show image\n",
        "plt.imshow(images_test[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.7.0\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1994 - accuracy: 0.9412\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1158 - accuracy: 0.9650\n",
            "[[1.1078785e-05 7.5603680e-07 2.1593696e-04 1.6498623e-03 1.6641291e-08\n",
            "  9.0921949e-06 1.5002435e-09 9.9804688e-01 1.2337908e-06 6.5105312e-05]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f11314dec10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UOplPxS8PPI",
        "outputId": "11c8fd4f-ac6e-4fd5-b2e8-e6afc7d88024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.predict(images_train[0].reshape(-1,28,28))\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1169712e-07, 3.1399807e-07, 2.0227046e-05, 1.9057885e-02,\n",
              "        2.1386530e-10, 9.8090875e-01, 4.2894914e-09, 1.0401401e-05,\n",
              "        5.0983616e-08, 1.8165424e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKQ7lTfIwkJi"
      },
      "source": [
        "## **Configuring Models for Training**\n",
        "\n",
        "\n",
        "There are many ways to configure a model to get the best performance and it often relies on a little trial and error. The following code snippets shows a couple of examples ofconfiguring a model for training:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Configure a model for mean-squared error regression.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
        "              loss='mse',# mean squared error\n",
        "              metrics=['mae'])# mean absolute error\n",
        "\n",
        "# Configure a model for categorical classification.\n",
        "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.categorical_accuracy])\n",
        "```\n",
        "\n",
        "## **Exercises**\n",
        "### **These problems are ALL or NONE. No partial credit on either exercise.**\n",
        "### **Exercise 1 (20 points)**\n",
        "\n",
        "Build a simple tf.keras neural network(one input, hidden and output layer) to implement an OR gate. The hidden and output layer should consist of a single neuron. The **output activation function should be a sigmoid**. You should solve this as a complete end-to-end machine learning problem including all steps in the workflow:\n",
        "\n",
        "\n",
        "*   Create the training data (features and labels)\n",
        "*   Build and stack the neural networks layers to create model\n",
        "*   Select loss function and optimizer to assess the prediction error\n",
        "*   Compile the model\n",
        "*   Show model archtecture\n",
        "*   Train the model\n",
        "*   Use the model's history to plot the loss and accuracy during training\n",
        "*   Check the model's prediction accuracy with test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JUMkFkC6znc",
        "outputId": "252f4c8a-1741-404a-dc91-f9f115a6efaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Create training dataset  \n",
        "x_train = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float')\n",
        "\n",
        "# Create training labels \n",
        "y_train = np.array([[0], [1], [1], [1] ], dtype = 'float')\n",
        "\n",
        "# model has an input layer and a hidden and output layer, each with one neuron (units)\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(units = 10 , input_shape = (2,)),\n",
        "        tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
        "])\n",
        "\n",
        "#compile the model\n",
        "learning_rate = 0.1\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr = learning_rate),\n",
        "    loss = tf.keras.losses.binary_crossentropy,\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "#show model architecture\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs= 100, verbose = 0)\n",
        "\n",
        "#plot the loss\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "test_set = [[0,0], [0,1], [1,0], [1,1]]\n",
        "\n",
        "print('The model predicts for the 4 inputs \\n', model.predict(test_set))\n",
        "\n",
        "print('\\nThe expected values are: [0] for [0,0] and [1] for [0,1], [1,0], and [1,1].')\n",
        "print('The model predicted correctly for all testing data.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 10)                30        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model predicts for the 4 inputs \n",
            " [[3.520011e-05]\n",
            " [9.999883e-01]\n",
            " [9.999882e-01]\n",
            " [1.000000e+00]]\n",
            "\n",
            "The expected values are: [0] for [0,0] and [1] for [0,1], [1,0], and [1,1].\n",
            "The model predicted correctly for all testing data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxkYYVZvx-lk"
      },
      "source": [
        "### **Exercise 2 (15 pts)**\n",
        "\n",
        "Rebuild the model from Exercise 1 by changing the **output activation function to a softmax**. You may also need to modify/change other parameters, optimizers and loss functions. Give a proper interpretation of your model's predictions. **Do all of the work here, including your imports, and, in not more than two cells**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0JYY20N8xc4",
        "outputId": "6aefe15e-57d4-4cc9-b3ca-84ab25355f50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Create training dataset  \n",
        "x_train = np.array([[0,0], [0,1], [1,0], [1,1]], dtype='float')\n",
        "\n",
        "# Create training labels \n",
        "y_train = np.array([[0], [1], [1], [1] ], dtype = 'float')\n",
        "\n",
        "# model has an input layer and a hidden and output layer, each with one neuron (units)\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(units = 10 , input_shape = (2,)),\n",
        "        tf.keras.layers.Dense(1, activation= 'softmax')\n",
        "])\n",
        "\n",
        "#compile the model\n",
        "learning_rate = 0.1\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.RMSprop(lr = learning_rate),\n",
        "    loss = tf.keras.losses.binary_crossentropy,\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "#show model architecture\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs= 1000, verbose = 0)\n",
        "\n",
        "test_set = [[0,0], [0,1],[1,0] , [1,1]]\n",
        "\n",
        "print('The model predicts for the 4 inputs \\n', model.predict(test_set))\n",
        "\n",
        "print('\\nThe expected values are: [0] for [0,0] and [1] for [0,1], [1,0], and [1,1].')\n",
        "print('The model did not predict correctly for all testing data.  The model predicted correctly for [0,1], [1,0], and [1,1].')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 10)                30        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f11353c10e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "The model predicts for the 4 inputs \n",
            " [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "\n",
            "The expected values are: [0] for [0,0] and [1] for [0,1], [1,0], and [1,1].\n",
            "The model did not predict correctly for all testing data.  The model predicted correctly for [0,1], [1,0], and [1,1].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne5cxTwoQtVp"
      },
      "source": [
        "**Even after trying different parameters for the compilation of the model, I was never able to get the model to correctly predict for the first input of the testing set: [0,0].  The model always predicted the value 1 for these values, but in an or gate the values [0,0] would correlate to an output of 0.**"
      ]
    }
  ]
}