{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5GwTC6xYNnN"
   },
   "source": [
    "\n",
    "\n",
    "# **Making A Speech Emotion Recognizer Using Python AndScikit-learn**\n",
    "\n",
    "### Paul Ritter and Anthony Teate\n",
    "\n",
    "### **Building a Speech Emotion Recognition system that detects emotion from human speech tone using the Scikit-Learn library,Python and Librosa**\n",
    "\n",
    "\n",
    "**What is Speech Emotion Recognition?**\n",
    "\n",
    "Speech Emotion Recognition, abbreviated as SER, is the act of attempting to recognize human emotion and affective states from speech.  This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is also the phenomenon that animals like dogs and horses employ to be able to understand human emotion.  SER is tough because emotions are subjective and annotating audio is challenging.\n",
    "\n",
    "**What is librosa?**\n",
    "\n",
    "librosa is a Python library for analyzing audio and music. It has a flatter package layout, standardizes interfaces and names, backwards compatibility, modular functions, and readable code. Further, in this Python mini-project, I demonstrate how to install it (and a few other packages) with pip.\n",
    "\n",
    "**Speech Emotion Recognition – Objective**\n",
    "\n",
    "To build a model to recognize emotion from speech using the librosa and sklearn libraries and the RAVDESS dataset.\n",
    "\n",
    "**Speech Emotion Recognition – About **\n",
    "\n",
    "In this Python mini project, I use the libraries librosa, soundfile, and sklearn (among others) to build a model using an MLPClassifier. This will be able to recognize emotion from sound files. I will load the data, extract features from it, then split the dataset into training and testing sets. Then, I will initialize an MLPClassifier and train the model. Finally, I calculate the accuracy of our model.\n",
    "\n",
    "**The Dataset**\n",
    "\n",
    "For this Python mini project, I use the RAVDESS dataset; this is the Ryerson Audio-Visual Database of Emotional Speech and Songdataset, and is free to download. This dataset has 7356 files rated by 247 individuals 10 times on emotional validity, intensity, and genuineness. The entire dataset is 24.8GB from 24 actors, but I’ve lowered the sample rate on all the files, and you can download from Canvas.\n",
    "\n",
    "**File Summary**\n",
    "\n",
    "In total, the RAVDESS collection includes 7356 files (2880+2024+1440+1012 files).\n",
    "\n",
    "**File naming convention**\n",
    "\n",
    "Each of the 7356 RAVDESS files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics:\n",
    "\n",
    "**Filename identifiers** \n",
    "\n",
    "\n",
    "\n",
    "*   Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "*   Vocal channel (01 = speech, 02 = song).\n",
    "*   Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = suprised\n",
    "*   Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "*   Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "*   Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "*   Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "*Filename example: 02-01-06-01-02-01-12.mp4*\n",
    "\n",
    "\n",
    "\n",
    "*   Video-only (02)\n",
    "*   Speech (01)\n",
    "*   Fearful\n",
    "*   Normal intensity (01)\n",
    "*   Statement \"dogs\" (02)\n",
    "*   1st Repetition (01)\n",
    "*   12th Actor (12)\n",
    "*   Female, as the actor ID number is even.\n",
    "\n",
    "Find more information on the file structure and filenames from Zenodo: [Filename References](https://zenodo.org/record/1188976#.X39l7pNKjb3)\n",
    "\n",
    "### **Prerequisites**\n",
    "\n",
    "Install the following libraries with pip:\n",
    "\n",
    "pip install librosa soundfile numpy sklearn pyaudio\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkTP7MSwNcHA"
   },
   "source": [
    "The whole pipeline is as follows (same as any machine learning pipeline):\n",
    "\n",
    "\n",
    "*   Preparing the Dataset: Here, I download and convert the dataset to be suited for extraction.\n",
    "*   Loading the Dataset: This process is about loading the dataset in Python which involves extracting audio features, such as obtaining\n",
    "*   Training the Model: After I prepare and load the dataset, I simply train it on a suited sklearn model.\n",
    "*   Testing the Model: Measuring how good our model is doing.\n",
    "\n",
    "\n",
    "\n",
    "## **Import the dependencies**\n",
    "\n",
    "1.   import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IG_LzMPJNbw7"
   },
   "outputs": [],
   "source": [
    "import soundfile # to read audio file\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import librosa # to extract speech features\n",
    "import glob\n",
    "import os\n",
    "import pickle # to save model after training \n",
    "from sklearn.model_selection import train_test_split # for splitting training and testing\n",
    "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RsApoCdPLbb"
   },
   "source": [
    "2.   Define a function extract_feature to extract the mfcc, chroma, and mel features from a sound file. This function takes 4 parameters-the file name and three Boolean parameters for the three features:\n",
    "3.   **mfcc**: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound\n",
    "4.   **chroma**: Pertains to the 12 different pitch classes\n",
    "5.   **mel**: Mel Spectrogram Frequency\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WLP-DdtmPIK1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma: \n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))     \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rXp0eQSSvZX"
   },
   "source": [
    "3. Define a dictionary to hold numbers and the emotions available in the RAVDESS dataset, and a list to hold those we want-calm, happy, fearful, disgust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J7u_36pmSs7m"
   },
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions = {\n",
    "    '01':'neutral',\n",
    "    '02':'calm',\n",
    "    '03':'happy',\n",
    "    '04':'sad',\n",
    "    '05':'angry',\n",
    "    '06':'fearful',\n",
    "    '07':'disgust',\n",
    "    '08':'surprised'\n",
    "}\n",
    "\n",
    "# Emotions to observe\n",
    "observed_emotions = ['calm', 'happy', 'fearful', 'disgust']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EFdO49oTVz1"
   },
   "source": [
    "4.   Load the data with a function load_data() – this takes in the relative size of the test set as parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IWpI2Q8KTT7Y"
   },
   "outputs": [],
   "source": [
    "# Load the data and extract features for each sound file\n",
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"ravdess-data/Actor_*/*.wav\"):\n",
    "        file_name = os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size = test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYdkJj1QX3AY"
   },
   "source": [
    "Using our emotions dictionary, this number is turned into an emotion, and the function checks whether this emotion is in the list of observed_emotions; if not, it continues to the next file. It makes a call to extract_feature and stores what is returned in ‘feature’. Then, it appends the feature to x and the emotion to y. So, the list x holds the features and y holds the emotions.\n",
    "\n",
    "Call the function train_test_split with these, the test size, and a random state value, and return that.\n",
    "\n",
    "5. Split the dataset into training and testing sets! Keep the test set 25% of everything and use the load_data function for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "-CtbeRBoXxsZ",
    "outputId": "a07cfe31-252a-4b8b-d9a8-d1cae5f000f2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = load_data(test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmOF1JZ9YVFM"
   },
   "source": [
    "6. Observe the shape of the training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DDRxteKRYXC0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDwhRYkmYqdo"
   },
   "source": [
    "7. And get the number of features extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MVLoXFawYqHS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlYCqla6ZUzW"
   },
   "source": [
    "8. Initialize an MLPClassifier. This is a Multi-layer Perceptron Classifier; it optimizes the log-loss function using different optimizers (lbfgs, adam or stochastic gradient descent). Recall that the MLPClassifier has an internal neural network for the purpose of classification, and is a feed-forward ANN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Tnnd2DD8Z5tz"
   },
   "outputs": [],
   "source": [
    "# Initialize the Multi Layer Perceptron Classifier\n",
    "model = MLPClassifier(solver='adam', alpha=0.005, batch_size=200, epsilon=1e-08,\n",
    "                      hidden_layer_sizes=(400,),learning_rate='adaptive', max_iter=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoDsWnpOZJD1"
   },
   "source": [
    "9. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u2g6WsVdaElz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.005, batch_size=200, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(400,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=700,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfnaCbUDaNDT"
   },
   "source": [
    "10. Plot the loss during training\n",
    "\n",
    "A loss function, also known as a cost function, takes into account the probabilities or uncertainty of a prediction based on how much the prediction varies from the true value. This gives a more nuanced view into how well the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i6sxq4x0aMSs"
   },
   "outputs": [],
   "source": [
    "loss_values = model.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(6, 4))\n",
    "plt.plot(loss_values, color=\"red\", label='training loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss');\n",
    "#legend\n",
    "plt.legend(loc='upper right')\n",
    "#title\n",
    "plt.title('Training Loss Per Epoch: Speech Emotion Recognition')\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. <b> Model Predictions </b>\n",
    "\n",
    "To calculate the accuracy of our model, call up the accuracy_score() function imported from sklearn. Finally, round the accuracy to 2 decimal places and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict for the test set\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. <b> Model Performance </b>\n",
    "\n",
    "To calculate the accuracy of the model, call up the accuracy_score() function we imported from sklearn. Finally, round the accuracy to 2 decimal places and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.04%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of our model\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred=y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accurracy: 76.04 %\n"
     ]
    }
   ],
   "source": [
    "print('test set accurracy: {0:.2f} %'.format(100*model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Peformance on a single waveform</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predictied emotion from the speech is: happy\n"
     ]
    }
   ],
   "source": [
    "print('The predictied emotion from the speech is: {}'      \n",
    "      .format(model.predict([x_test[22]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true emotion is: happy\n"
     ]
    }
   ],
   "source": [
    "print('The true emotion is: {}'.format(y_test[22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pickle (serialize) and save the trained classifier to a folder </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialization with Python's Pickle\n",
    "import pickle \n",
    "import os\n",
    "\n",
    "dest=os.path.join('classifiers', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "    \n",
    "pickle.dump(model, open(os.path.join(dest, 'ser_classifier.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load the saved classifier into memory </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved the trained classifier into memory\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "os.chdir('classifiers')\n",
    "ser_model=pickle.load(open(os.path.join('pkl_objects', 'ser_classifier.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Test the re-loaded model </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reloaded model predicts the  emotion from the speech is:disgust\n"
     ]
    }
   ],
   "source": [
    "print('The reloaded model predicts the  emotion from the speech is:{}'      \n",
    "      .format(ser_model.predict([x_test[33]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true emotion is: disgust\n"
     ]
    }
   ],
   "source": [
    "print('The true emotion is: {}'.format(y_test[33]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Summary </b> \n",
    "\n",
    "In this Python, Machine Learning, Mini-Project, we learned to recognize emotions from speech. We used an MLPClassifier for the neural netwoerk and and made use of the soundfile library to read the sound file, and the librosa library to extract features from it.  We also serialized the model and tested the reloaded model on unseen data and saw that it performed well. So, as you've seen, the model delivered an accuracy of 70-80%, which is not bad for our first attempt at building a speech emotion recognizer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mini-Project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
